{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here, we worked to optimize our svm algo & complete our svm class by adding fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use('ggplot')\n",
    "\n",
    "#defining a class for our each support vectors\n",
    "class Support_Vector_Machine:\n",
    "    def __init__(self, visualization=True):                #this is the constructor.....need to see, so visualization\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'orange', -1:'yellow'}\n",
    "        \n",
    "        if self.visualization:                             #this is just to plot and see a simple support vector\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "        \n",
    "    def fit(self, data):                                   #this to train on the data and find the w and b\n",
    "        self.data = data\n",
    "        \n",
    "        opt_dict = {}                                      #the dictionary to store all values of vct w and its corresponding (max)b\n",
    "        \n",
    "        transform = [[1,1],[-1,1],[-1,-1],[1,-1]]          #the transformation matrix to change values of EACH w, \n",
    "                                                           #to take differnet directions of w each same magnitude\n",
    "            \n",
    "        all_data = []                                      #required to know WHERE to initialize our w and b in each step, by knowing max and min of them\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset:\n",
    "                    all_data.append(feature)\n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "        \n",
    "        step_sizes = [self.max_feature_value * 0.1,         #to get our w's step size.....but last one wud b very expensive\n",
    "                     self.max_feature_value * 0.01,\n",
    "                     self.max_feature_value * 0.001]\n",
    "        \n",
    "        b_range_multiple = 5                                #not needed to be very precise, so very big\n",
    "        b_multiple = 5\n",
    "        latest_optimum = self.max_feature_value * 10        #the first value for the vct w\n",
    "        \n",
    "        for step in step_sizes:                              #dropping different w's into the bowl of convex problem\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            optimized = False                               #this will stay Flase until no more w to step down, we got our w\n",
    "            \n",
    "            while not optimized:                            #the main optimization for min w and max b for each w\n",
    "                for b in arange(-1*self.max_feature_value*b_range_multiple, self.max_feature_value*b_range_multiple, \n",
    "                               step*b_multiple):            #this for loop to loop thru b's values, for each w\n",
    "                    for transformation in transform:        #changing direction for each w\n",
    "                        w_t = w * transformation\n",
    "                        found_option = True\n",
    "                                                            #the loop for ALL training data to b used by this b and this w\n",
    "                                                            #in EVERY case to see if main constraint yi(xi.w+b)>=1 fulfills\n",
    "                                                            #so even if ONE data does not fit, we throw the whole class/w out\n",
    "                        for i in self.data:                 \n",
    "                            for xi in self.data[i]:\n",
    "                                yi = i\n",
    "                                if not yi( np.dot(w_t,xi) + b ) >= 1:\n",
    "                                    fond_option = False\n",
    "                                                            #if we found a value, then we save it in the dictionary\n",
    "                                                            #with the w's magnitude as the index\n",
    "                        if found_option:\n",
    "                            opt_dict[np.np.linalg.norm(w_t)] = [w_t, b]\n",
    "                                                            #NOW, finishing after checking for every b in each w's transformation\n",
    "                                                            #we now check if its optimized ro we step-down our vct w\n",
    "                if w[0] < 0:\n",
    "                    optimized = True\n",
    "                    print ('optimized a value')\n",
    "                else: w = w - step\n",
    "        \n",
    "            norms = [sorted([n for n in opt_dict])]         #sorted out the dictionary, and took the vct, w, with min magnitude\n",
    "            opt_choice = opt_dict(norms[0])        \n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "        \n",
    "            latest_optimum = opt_choice[0][0] + step*2\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def predict(self, features):                           #this is to predict for an unknown feature\n",
    "    # we actually need to find the sign of (x.w + b), so we do this by using numpy's function follow:\n",
    "        classification = np.sign( np.dot(np.array(features) , self.w) + self.b )\n",
    "        return classification        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = {-1:np.array([[1,7],\n",
    "                          [2,8],\n",
    "                          [3,8]]),\n",
    "             1:np.array([[5,1],\n",
    "                         [6,-1],\n",
    "                         [7,3]])}\n",
    "#declaring a dictionary with two classes +1 and -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
